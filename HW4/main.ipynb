{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import solution as sol\n",
    "from PIL import Image, ImageDraw\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "def MatchRANSAC(\n",
    "        image1, image2, ratio_thres, orient_agreement, scale_agreement):\n",
    "    \"\"\"\n",
    "    Read two images and their associated SIFT keypoints and descriptors.\n",
    "    Find matches between images based on acos distance.\n",
    "    Filter a subset of matches using RANSAC\n",
    "    Display the final matches.\n",
    "    HINT: See main_match.py on how to use this function.\n",
    "    \"\"\"\n",
    "    im1, keypoints1, descriptors1 = ReadKeys(image1)\n",
    "    im2, keypoints2, descriptors2 = ReadKeys(image2)\n",
    "\n",
    "    keypoints1 = np.stack(keypoints1, axis=0)\n",
    "    keypoints2 = np.stack(keypoints2, axis=0)\n",
    "    matched_pairs = sol.FindBestMatchesRANSAC(\n",
    "        keypoints1, keypoints2,\n",
    "        descriptors1, descriptors2,\n",
    "        ratio_thres, orient_agreement, scale_agreement)\n",
    "    matched_pairs = [\n",
    "        [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
    "    assert len(matched_pairs) > 0, \"No match received\"\n",
    "    im3 = DisplayMatches(im1, im2, matched_pairs)\n",
    "    return im3\n",
    "\n",
    "\n",
    "def Match(image1, image2, ratio_thres):\n",
    "    \"\"\"\n",
    "    Read two images and their associated SIFT keypoints and descriptors.\n",
    "    Find matches between images based on acos distance.\n",
    "    Display the final matches.\n",
    "    HINT: See main_match.py on how to use this function.\n",
    "    \"\"\"\n",
    "    im1, keypoints1, descriptors1 = ReadKeys(image1)\n",
    "    im2, keypoints2, descriptors2 = ReadKeys(image2)\n",
    "\n",
    "    matched_pairs = sol.FindBestMatches(\n",
    "        descriptors1, descriptors2, ratio_thres)\n",
    "    matched_pairs = [\n",
    "        [keypoints1[i], keypoints2[j]] for (i, j) in matched_pairs]\n",
    "    assert len(matched_pairs) > 0, \"No match received\"\n",
    "    im3 = DisplayMatches(im1, im2, matched_pairs)\n",
    "    return im3\n",
    "\n",
    "\n",
    "def ReadKeys(image):\n",
    "    \"\"\"Input an image and its associated SIFT keypoints.\n",
    "\n",
    "    The argument image is the image file name (without an extension).\n",
    "    The image is read from the PGM format file image.pgm and the\n",
    "    keypoints are read from the file image.key.\n",
    "\n",
    "    ReadKeys returns the following 3 arguments:\n",
    "\n",
    "    image: the image (in PIL 'RGB' format)\n",
    "\n",
    "    keypoints: K-by-4 array, in which each row has the 4 values specifying\n",
    "    a keypoint (row, column, scale, orientation).  The orientation\n",
    "    is in the range [-PI, PI] radians.\n",
    "\n",
    "    descriptors: a K-by-128 array, where each row gives a descriptor\n",
    "    for one of the K keypoints.  The descriptor is a 1D array of 128\n",
    "    values with unit length.\n",
    "    \"\"\"\n",
    "    im = Image.open(image+'.pgm').convert('RGB')\n",
    "    keypoints = []\n",
    "    descriptors = []\n",
    "    first = True\n",
    "    with open(image+'.key','r') as f:\n",
    "        reader = csv.reader(f, delimiter=' ', quoting=csv.QUOTE_NONNUMERIC,skipinitialspace = True)\n",
    "        descriptor = []\n",
    "        for row in reader:\n",
    "            if len(row) == 2:\n",
    "                assert first, \"Invalid keypoint file header.\"\n",
    "                assert row[1] == 128, \"Invalid keypoint descriptor length in header (should be 128).\"\n",
    "                count = row[0]\n",
    "                first = False\n",
    "            if len(row) == 4:\n",
    "                keypoints.append(np.array(row))\n",
    "            if len(row) == 20:\n",
    "                descriptor += row\n",
    "            if len(row) == 8:\n",
    "                descriptor += row\n",
    "                assert len(descriptor) == 128, \"Keypoint descriptor length invalid (should be 128).\"\n",
    "                #normalize the key to unit length\n",
    "                descriptor = np.array(descriptor)\n",
    "                descriptor = descriptor / math.sqrt(np.sum(np.power(descriptor,2)))\n",
    "                descriptors.append(descriptor)\n",
    "                descriptor = []\n",
    "    #assert len(keypoints) == count, \"Incorrect total number of keypoints read.\"\n",
    "    print(\"Number of keypoints read:\", int(count))\n",
    "    descriptors = np.stack(descriptors, axis=0)\n",
    "    return [im,keypoints,descriptors]\n",
    "\n",
    "\n",
    "def AppendImages(im1, im2):\n",
    "    \"\"\"Create a new image that appends two images side-by-side.\n",
    "\n",
    "    The arguments, im1 and im2, are PIL images of type RGB\n",
    "    \"\"\"\n",
    "    im1cols, im1rows = im1.size\n",
    "    im2cols, im2rows = im2.size\n",
    "    im3 = Image.new('RGB', (im1cols+im2cols, max(im1rows,im2rows)))\n",
    "    im3.paste(im1,(0,0))\n",
    "    im3.paste(im2,(im1cols,0))\n",
    "    return im3\n",
    "\n",
    "def DisplayMatches(im1, im2, matched_pairs):\n",
    "    \"\"\"Display matches on a new image with the two input images placed side by side.\n",
    "\n",
    "    Arguments:\n",
    "     im1           1st image (in PIL 'RGB' format)\n",
    "     im2           2nd image (in PIL 'RGB' format)\n",
    "     matched_pairs list of matching keypoints, im1 to im2\n",
    "\n",
    "    Displays and returns a newly created image (in PIL 'RGB' format)\n",
    "    \"\"\"\n",
    "    im3 = AppendImages(im1,im2)\n",
    "    offset = im1.size[0]\n",
    "    draw = ImageDraw.Draw(im3)\n",
    "    for match in matched_pairs:\n",
    "        draw.line((match[0][1], match[0][0], offset+match[1][1], match[1][0]),fill=\"red\",width=2)\n",
    "    im3.show()\n",
    "    return im3\n",
    "\n",
    "\n",
    "def ReadData(fname):\n",
    "    \"\"\"\n",
    "    Given the fname, return the image, keypoints, and descriptors.\n",
    "    Note: the fname should be a path of the image, but with no extensions.\n",
    "    For example, '/my/path/ubc.png' should be '/my/path/ubc'\n",
    "    \"\"\"\n",
    "    with open(fname + '.pkl', 'rb') as f:\n",
    "        data = pkl.load(f)\n",
    "    im = Image.open(fname + '.png').convert('RGB')\n",
    "    keypoints = data['keypoints']\n",
    "    descriptors = data['descriptors']\n",
    "    return [im, keypoints, descriptors]\n",
    "\n",
    "\n",
    "def FindBestMatchesXY(im_src_path, im_ref_path, ratio_thres):\n",
    "    \"\"\"\n",
    "    This function takes two image paths, fetch the corresponding keypoints\n",
    "    of the two image paths, find the best matches between keypoints\n",
    "    and return the keypoint correspondances in xy coordinates.\n",
    "    Inputs:\n",
    "        im_src_path: the path of the source image.\n",
    "        im_ref_path: the path of the image considered as the reference frame.\n",
    "        ratio_thres: threshold for ratio test.\n",
    "    Outputs:\n",
    "        xy_src: numpy array, (matches, 2), xy coordinates of keypoints in source.\n",
    "        xy_ref: numpy array, (matches, 2), xy coordinates of keypoints in ref.\n",
    "    \"\"\"\n",
    "    assert isinstance(im_src_path, str)\n",
    "    assert isinstance(im_ref_path, str)\n",
    "    assert isinstance(ratio_thres, float)\n",
    "    _, keypoints1, descriptors1 = ReadData(im_src_path)\n",
    "    _, keypoints2, descriptors2 = ReadData(im_ref_path)\n",
    "    matches = list(sol.FindBestMatches(descriptors1, descriptors2, ratio_thres))\n",
    "    matches = [(keypoints1[i1], keypoints2[i2]) for (i1, i2) in matches]\n",
    "\n",
    "    # Extract the xy of the matches\n",
    "    yx_src, yx_ref = zip(*[(match[0][:2], match[1][:2]) for match in matches])\n",
    "    xy_src = np.array(yx_src)[:, [1, 0]]  # yx to xy\n",
    "    xy_ref = np.array(yx_ref)[:, [1, 0]]\n",
    "    return xy_src, xy_ref\n",
    "\n",
    "\n",
    "def PrepareData(image_list, ratio_thres):\n",
    "    \"\"\"\n",
    "    This function takes in a list of image paths of interests;\n",
    "    Extracts the keypoints correspondance between the reference image and all other images.\n",
    "    The first image on the image_list is the reference image.\n",
    "    Note: there is no RANSAC performed.\n",
    "    Inputs:\n",
    "        image_list: a list of paths to the images (with no extensions)\n",
    "        ratio_thres: the threshold for doing the ratio test of keypoint correspondance.\n",
    "    Outputs:\n",
    "        xy_src_list: numpy array, (num_matches, 2)\n",
    "        xy_ref_list: numpy array, (num_matches, 2)\n",
    "        im_list: a list of np.array, where each np.array is an image.\n",
    "    \"\"\"\n",
    "    assert isinstance(image_list, list)\n",
    "    assert len(image_list) > 1, \"Need at leat two images to do stiching\"\n",
    "    assert isinstance(image_list[0], str)\n",
    "    assert isinstance(ratio_thres, float)\n",
    "    assert ratio_thres >= 0.0\n",
    "    assert ratio_thres <= 1.0\n",
    "\n",
    "    xy_src_list = []\n",
    "    xy_ref_list = []\n",
    "    ref_image = image_list[0]\n",
    "    image_list = image_list[1:]\n",
    "    for src_image in image_list:\n",
    "        xy_src, xy_ref = FindBestMatchesXY(\n",
    "            src_image, ref_image, ratio_thres)\n",
    "        if xy_src.shape[0] >= 4:\n",
    "            xy_src_list.append(xy_src)\n",
    "            xy_ref_list.append(xy_ref)\n",
    "\n",
    "    im_ref, _, _ = ReadData(ref_image)\n",
    "    im_list = [np.array(im_ref)] + [\n",
    "        np.array(ReadData(img)[0]) for img in image_list]\n",
    "    return xy_src_list, xy_ref_list, im_list\n",
    "\n",
    "\n",
    "def MergeWarppedImages(canvas_height, canvas_width, warp_list):\n",
    "    \"\"\"\n",
    "    Wrap a list of images in the reference frame into one canvas.\n",
    "    Note:\n",
    "        each image is a numpy array of shape (canvas_height, canvas_width, 3)\n",
    "        The first image in the warp_list is the reference image\n",
    "    \"\"\"\n",
    "    assert isinstance(canvas_height, int)\n",
    "    assert isinstance(canvas_width, int)\n",
    "    assert isinstance(warp_list, list)\n",
    "\n",
    "    canvas = np.zeros((canvas_height, canvas_width, 3), dtype=np.uint8)\n",
    "\n",
    "    im_ref = warp_list[0]  # reference image in reference frame\n",
    "    assert im_ref.dtype == np.uint8\n",
    "    canvas[:im_ref.shape[0], :im_ref.shape[1]] = im_ref\n",
    "    alpha = 0.5\n",
    "    for wrap in warp_list[1:]:\n",
    "        assert isinstance(wrap, np.ndarray)\n",
    "        assert wrap.shape == canvas.shape\n",
    "        assert wrap.dtype == np.uint8\n",
    "        mask_wrap = Image.fromarray(wrap).convert('L')\n",
    "        mask_wrap = np.array(mask_wrap) > 0\n",
    "\n",
    "        mask_canvas = Image.fromarray(canvas).convert('L')\n",
    "        mask_canvas = np.array(mask_canvas) > 0\n",
    "\n",
    "        mask_intersect = np.logical_and(mask_canvas, mask_wrap)\n",
    "\n",
    "        # blend in intersected area\n",
    "        canvas[mask_intersect] = (\n",
    "                alpha*canvas[mask_intersect] +\n",
    "                (1-alpha)*wrap[mask_intersect]).astype(np.uint8)\n",
    "        canvas[mask_intersect] = (\n",
    "                alpha*canvas[mask_intersect] +\n",
    "                (1-alpha)*wrap[mask_intersect]).astype(np.uint8)\n",
    "\n",
    "        # copy in non-interected area\n",
    "        mask_empty = np.logical_not(mask_intersect)\n",
    "        canvas[mask_empty] += wrap[mask_empty]\n",
    "    return canvas\n",
    "\n",
    "\n",
    "def ProjectImages(\n",
    "        xy_src_list, xy_ref_list, im_list,\n",
    "        canvas_height, canvas_width, num_iter, tol):\n",
    "    \"\"\"\n",
    "    This function takes in a list of images, and the points correspondance between\n",
    "    the reference image and other images; computes the homography from every source\n",
    "    image to the reference image using RANSAC; warp each source image to the reference\n",
    "    image frame using each homography computed.\n",
    "    Inputs:\n",
    "        xy_src_list: a list of np array, each element is keypoint correspondance\n",
    "                     between a source image to the reference image, in xy coordinates.\n",
    "        xy_ref_list: a list of np array, each element is keypoint correspondance\n",
    "                     between a source image to the reference image, in xy coordinates.\n",
    "        im_list: all images in np.array form, the firs element is the reference image.\n",
    "        canvas_height, canvas_width: the dimension of the canvas to copy the warps over.\n",
    "        num_iter: number of RANSAC iterations in RANSACHomography\n",
    "        tol: the Euclidean tolerance for keypoints matching projection.\n",
    "    Outputs:\n",
    "        A list of images in np.array form after they have been projected to\n",
    "        the reference frame.\n",
    "    \"\"\"\n",
    "    assert isinstance(xy_src_list, list)\n",
    "    assert isinstance(xy_ref_list, list)\n",
    "    assert isinstance(im_list, list)\n",
    "    assert isinstance(canvas_height, int)\n",
    "    assert isinstance(canvas_width, int)\n",
    "    assert isinstance(num_iter, int)\n",
    "    assert isinstance(tol, (int, float))\n",
    "    assert len(xy_src_list) == len(xy_ref_list)\n",
    "    assert len(xy_src_list) + 1 == len(im_list), \\\n",
    "        \"Num of source images + 1 == num of all images\"\n",
    "\n",
    "    homo_list = []\n",
    "    for xy_src, xy_ref in zip(xy_src_list, xy_ref_list):\n",
    "        h = sol.RANSACHomography(xy_src, xy_ref, num_iter, tol)\n",
    "        homo_list.append(h)\n",
    "    warp_list = [im_list[0]]\n",
    "    im_list = im_list[1:]\n",
    "    assert len(im_list) == len(homo_list)\n",
    "    for im, h in zip(im_list, homo_list):\n",
    "        result = cv2.warpPerspective(im, h, (canvas_width, canvas_height))\n",
    "        warp_list.append(result)\n",
    "    return warp_list\n",
    "\n",
    "\n",
    "def VisualizePointProj(xy_src, xy_ref, xy_proj, im_src, im_ref):\n",
    "    assert isinstance(xy_src, np.ndarray)\n",
    "    assert isinstance(xy_ref, np.ndarray)\n",
    "    assert isinstance(xy_proj, np.ndarray)\n",
    "    assert isinstance(im_src, np.ndarray)\n",
    "    assert isinstance(im_ref, np.ndarray)\n",
    "    assert xy_src.shape == xy_ref.shape\n",
    "    assert xy_src.shape == xy_proj.shape\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2, figsize=(30, 30), gridspec_kw={'width_ratios': [1, 2]})\n",
    "    for xy_a, xy_b in zip(xy_proj, xy_ref):\n",
    "        x1, y1 = xy_a\n",
    "        x2, y2 = xy_b\n",
    "        axes[1].plot([x1, x2],[y1, y2], 'w-', linewidth=2)\n",
    "\n",
    "    axes[0].imshow(im_src)\n",
    "    axes[0].scatter(xy_src[:, 0], xy_src[:, 1], c='#fafba4', s=100, marker='.')\n",
    "    axes[0].title.set_text('Source Image')\n",
    "\n",
    "    axes[1].imshow(im_ref)\n",
    "    axes[1].scatter(xy_proj[:, 0], xy_proj[:, 1], c='#fafba4', s=100, marker='.')\n",
    "    axes[1].scatter(xy_ref[:, 0], xy_ref[:, 1], c='#d63447', s=100, marker='.')\n",
    "    axes[1].title.set_text('Reference Image')\n",
    "    fig.show()\n",
    "    input('Press any key to exit the program')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "def RANSACFilter(\n",
    "        matched_pairs, keypoints1, keypoints2,\n",
    "        orient_agreement, scale_agreement):\n",
    "    \"\"\"\n",
    "    This function takes in `matched_pairs`, a list of matches in indices\n",
    "    and return a subset of the pairs using RANSAC.\n",
    "    Inputs:\n",
    "        matched_pairs: a list of tuples [(i, j)],\n",
    "            indicating keypoints1[i] is matched\n",
    "            with keypoints2[j]\n",
    "        keypoints1, 2: keypoints from image 1 and image 2\n",
    "            stored in np.array with shape (num_pts, 4)\n",
    "            each row: row, col, scale, orientation\n",
    "        *_agreement: thresholds for defining inliers, floats\n",
    "    Output:\n",
    "        largest_set: the largest consensus set in [(i, j)] format\n",
    "\n",
    "    HINTS: the \"*_agreement\" definitions are well-explained\n",
    "           in the assignment instructions.\n",
    "    \"\"\"\n",
    "    assert isinstance(matched_pairs, list)\n",
    "    assert isinstance(keypoints1, np.ndarray)\n",
    "    assert isinstance(keypoints2, np.ndarray)\n",
    "    assert isinstance(orient_agreement, float)\n",
    "    assert isinstance(scale_agreement, float)\n",
    "    ## START\n",
    "    largest_set = []\n",
    "    for i in range(10):  # repeat ten times\n",
    "        rand = random.randrange(0, len(matched_pairs))  # generate random number\n",
    "        choice = matched_pairs[rand]\n",
    "        orientation = (keypoints1[choice[0]][3] - keypoints2[choice[1]][3]) % (\n",
    "                2 * math.pi)  # calculation first-orientation\n",
    "        scale = keypoints2[choice[1]][2] / keypoints1[choice[0]][2]  # calculation first-scale ratio\n",
    "        temp = []\n",
    "        for j in range(len(matched_pairs)):  # calculate the number of all cases\n",
    "            if j is not rand:\n",
    "                # calculation second-orientation\n",
    "                orientation_temp = (keypoints1[matched_pairs[j][0]][3] - keypoints2[matched_pairs[j][1]][3]) % (\n",
    "                        2 * math.pi)\n",
    "                # calculation second-scale-ratio\n",
    "                scale_temp = keypoints2[matched_pairs[j][1]][2] / keypoints1[matched_pairs[j][0]][2]\n",
    "                # check degree error +=30degree\n",
    "                if ((orientation - math.pi / 6) < orientation_temp) and (\n",
    "                        orientation_temp < (orientation + math.pi / 6)):\n",
    "                    # check scale error +- 50%\n",
    "                    if scale - scale * scale_agreement < scale_temp < scale + scale * scale_agreement:\n",
    "                        temp.append([i, j])\n",
    "        if len(temp) > len(largest_set):\n",
    "            largest_set = temp\n",
    "    for i in range(len(largest_set)):\n",
    "        largest_set[i] = (matched_pairs[largest_set[i][1]][0], matched_pairs[largest_set[i][1]][1])\n",
    "\n",
    "    ## END\n",
    "    assert isinstance(largest_set, list)\n",
    "    return largest_set\n",
    "\n",
    "\n",
    "def FindBestMatches(descriptors1, descriptors2, threshold):\n",
    "    \"\"\"\n",
    "    This function takes in descriptors of image 1 and image 2,\n",
    "    and find matches between them. See assignment instructions for details.\n",
    "    Inputs:\n",
    "        descriptors: a K-by-128 array, where each row gives a descriptor\n",
    "        for one of the K keypoints.  The descriptor is a 1D array of 128\n",
    "        values with unit length.\n",
    "        threshold: the threshold for the ratio test of \"the distance to the nearest\"\n",
    "                   divided by \"the distance to the second nearest neighbour\".\n",
    "                   pseudocode-wise: dist[best_idx]/dist[second_idx] <= threshold\n",
    "    Outputs:\n",
    "        matched_pairs: a list in the form [(i, j)] where i and j means\n",
    "                       descriptors1[i] is matched with descriptors2[j].\n",
    "    \"\"\"\n",
    "    assert isinstance(descriptors1, np.ndarray)\n",
    "    assert isinstance(descriptors2, np.ndarray)\n",
    "    assert isinstance(threshold, float)\n",
    "    ## START\n",
    "    ## the following is just a placeholder to show you the output format\n",
    "    y1 = descriptors1.shape[0]  # 해당 코드는 descriptor1 의 요소들을 순회하기 위해서 필요함\n",
    "    y2 = descriptors2.shape[1]  # 해당 코드는 descriptor2 의 요소들을 순회하기 위해서 필요함\n",
    "    temp = np.zeros(y2)\n",
    "    matched_pairs = []\n",
    "\n",
    "    for i1 in range(y1):\n",
    "        for i2 in range(y2):\n",
    "            temp[i2] = math.acos(np.dot(descriptors1[i1], descriptors2[i2]))\n",
    "        compare = sorted(range(len(temp)), key=lambda k: temp[k])\n",
    "        if (temp[compare[0]] / temp[compare[1]]) < threshold:\n",
    "            matched_pairs.append([i1, compare[0]])\n",
    "    ## END\n",
    "    return matched_pairs\n",
    "\n",
    "\n",
    "def KeypointProjection(xy_points, h):\n",
    "    \"\"\"\n",
    "    This function projects a list of points in the source image to the\n",
    "    reference image using a homography matrix `h`.\n",
    "    Inputs:\n",
    "        xy_points: numpy array, (num_points, 2)\n",
    "        h: numpy array, (3, 3), the homography matrix\n",
    "    Output:\n",
    "        xy_points_out: numpy array, (num_points, 2), input points in\n",
    "        the reference frame.\n",
    "    \"\"\"\n",
    "    assert isinstance(xy_points, np.ndarray)\n",
    "    assert isinstance(h, np.ndarray)\n",
    "    assert xy_points.shape[1] == 2\n",
    "    assert h.shape == (3, 3)\n",
    "\n",
    "    # START\n",
    "\n",
    "    # END\n",
    "    return xy_points_out\n",
    "\n",
    "\n",
    "def RANSACHomography(xy_src, xy_ref, num_iter, tol):\n",
    "    \"\"\"\n",
    "    Given matches of keyponit xy coordinates, perform RANSAC to obtain\n",
    "    the homography matrix. At each iteration, this function randomly\n",
    "    choose 4 matches from xy_src and xy_ref.  Compute the homography matrix\n",
    "    using the 4 matches.  Project all source \"xy_src\" keypoints to the\n",
    "    reference image.  Check how many projected keyponits are within a `tol`\n",
    "    radius to the coresponding xy_ref points (a.k.a. inliers).  During the\n",
    "    iterations, you should keep track of the iteration that yields the largest\n",
    "    inlier set. After the iterations, you should use the biggest inlier set to\n",
    "    compute the final homography matrix.\n",
    "    Inputs:\n",
    "        xy_src: a numpy array of xy coordinates, (num_matches, 2)\n",
    "        xy_ref: a numpy array of xy coordinates, (num_matches, 2)\n",
    "        num_iter: number of RANSAC iterations.\n",
    "        tol: float\n",
    "    Outputs:\n",
    "        h: The final homography matrix.\n",
    "    \"\"\"\n",
    "    assert isinstance(xy_src, np.ndarray)\n",
    "    assert isinstance(xy_ref, np.ndarray)\n",
    "    assert xy_src.shape == xy_ref.shape\n",
    "    assert xy_src.shape[1] == 2\n",
    "    assert isinstance(num_iter, int)\n",
    "    assert isinstance(tol, (int, float))\n",
    "    tol = tol * 1.0\n",
    "\n",
    "    # START\n",
    "\n",
    "    # END\n",
    "    assert isinstance(h, np.ndarray)\n",
    "    assert h.shape == (3, 3)\n",
    "    return h\n",
    "\n",
    "\n",
    "def FindBestMatchesRANSAC(\n",
    "        keypoints1, keypoints2,\n",
    "        descriptors1, descriptors2, threshold,\n",
    "        orient_agreement, scale_agreement):\n",
    "    \"\"\"\n",
    "    Note: you do not need to change this function.\n",
    "    However, we recommend you to study this function carefully\n",
    "    to understand how each component interacts with each other.\n",
    "\n",
    "    This function find the best matches between two images using RANSAC.\n",
    "    Inputs:\n",
    "        keypoints1, 2: keypoints from image 1 and image 2\n",
    "            stored in np.array with shape (num_pts, 4)\n",
    "            each row: row, col, scale, orientation\n",
    "        descriptors1, 2: a K-by-128 array, where each row gives a descriptor\n",
    "        for one of the K keypoints.  The descriptor is a 1D array of 128\n",
    "        values with unit length.\n",
    "        threshold: the threshold for the ratio test of \"the distance to the nearest\"\n",
    "                   divided by \"the distance to the second nearest neighbour\".\n",
    "                   pseudocode-wise: dist[best_idx]/dist[second_idx] <= threshold\n",
    "        orient_agreement: in degrees, say 30 degrees.\n",
    "        scale_agreement: in floating points, say 0.5\n",
    "    Outputs:\n",
    "        matched_pairs_ransac: a list in the form [(i, j)] where i and j means\n",
    "        descriptors1[i] is matched with descriptors2[j].\n",
    "    Detailed instructions are on the assignment website\n",
    "    \"\"\"\n",
    "    orient_agreement = float(orient_agreement)\n",
    "    assert isinstance(keypoints1, np.ndarray)\n",
    "    assert isinstance(keypoints2, np.ndarray)\n",
    "    assert isinstance(descriptors1, np.ndarray)\n",
    "    assert isinstance(descriptors2, np.ndarray)\n",
    "    assert isinstance(threshold, float)\n",
    "    assert isinstance(orient_agreement, float)\n",
    "    assert isinstance(scale_agreement, float)\n",
    "    matched_pairs = FindBestMatches(\n",
    "        descriptors1, descriptors2, threshold)\n",
    "    matched_pairs_ransac = RANSACFilter(\n",
    "        matched_pairs, keypoints1, keypoints2,\n",
    "        orient_agreement, scale_agreement)\n",
    "    return matched_pairs_ransac\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keypoints read: 694\n",
      "Number of keypoints read: 490\n",
      "Number of keypoints read: 1766\n",
      "Number of keypoints read: 849\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "No match received",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 25\u001B[0m\n\u001B[1;32m     21\u001B[0m                 plt\u001B[38;5;241m.\u001B[39mimshow(im)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 25\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[3], line 17\u001B[0m, in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m     16\u001B[0m     plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m20\u001B[39m, \u001B[38;5;241m20\u001B[39m))\n\u001B[0;32m---> 17\u001B[0m     im \u001B[38;5;241m=\u001B[39m \u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMatchRANSAC\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data/library\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./data/library2\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m        \u001B[49m\u001B[43mratio_thres\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m0.05\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morient_agreement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale_agreement\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.2\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m0.05\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m     plt\u001B[38;5;241m.\u001B[39mtitle(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMatchRANSAC\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     21\u001B[0m     plt\u001B[38;5;241m.\u001B[39mimshow(im)\n",
      "File \u001B[0;32m~/Desktop/ComputerVision/HW4/hw_utils.py:33\u001B[0m, in \u001B[0;36mMatchRANSAC\u001B[0;34m(image1, image2, ratio_thres, orient_agreement, scale_agreement)\u001B[0m\n\u001B[1;32m     27\u001B[0m matched_pairs \u001B[38;5;241m=\u001B[39m sol\u001B[38;5;241m.\u001B[39mFindBestMatchesRANSAC(\n\u001B[1;32m     28\u001B[0m     keypoints1, keypoints2,\n\u001B[1;32m     29\u001B[0m     descriptors1, descriptors2,\n\u001B[1;32m     30\u001B[0m     ratio_thres, orient_agreement, scale_agreement)\n\u001B[1;32m     31\u001B[0m matched_pairs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     32\u001B[0m     [keypoints1[i], keypoints2[j]] \u001B[38;5;28;01mfor\u001B[39;00m (i, j) \u001B[38;5;129;01min\u001B[39;00m matched_pairs]\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(matched_pairs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo match received\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     34\u001B[0m im3 \u001B[38;5;241m=\u001B[39m DisplayMatches(im1, im2, matched_pairs)\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m im3\n",
      "\u001B[0;31mAssertionError\u001B[0m: No match received"
     ]
    }
   ],
   "source": [
    "import hw_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Test run matching with no ransac\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    im = utils.Match('./data/scene', './data/book', ratio_thres=0.6)\n",
    "    plt.title('Match')\n",
    "    plt.imshow(im)\n",
    "\n",
    "    # Test run matching with ransac\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            for k in range(10):\n",
    "                plt.figure(figsize=(20, 20))\n",
    "                print(\"i = {} : j = {} : k = {}\".format(i, j, k))\n",
    "                im = utils.MatchRANSAC(\n",
    "                    './data/library', './data/library2',\n",
    "                    ratio_thres=0.5+0.05*i, orient_agreement=30+3*j, scale_agreement=0.2+0.05*k)\n",
    "                plt.title('MatchRANSAC')\n",
    "                plt.imshow(im)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
