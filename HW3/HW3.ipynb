{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "mapped_sum_gradient_iguanaet and use the functions associated with gaussconvolve2d that you used in the last HW02.\n",
    "\"\"\"\n",
    "def gauss1d(sigma):\n",
    "    width: int = int(math.ceil(6 * sigma))  # 6*sigma의 다음 정수로 width를 설정\n",
    "    if width % 2 == 0:  # 다음 정수가 짝수라면 +1 하여 홀수로 변경\n",
    "        width += 1\n",
    "\n",
    "    center = math.floor(width / 2)  # 가운데 index를 획득\n",
    "    gaussian = np.zeros((1, width)).flatten()  # 반환할 1D Numpy Array 생성\n",
    "    for i in range(width):\n",
    "        gaussian[i] = i - center  # Hint:를 토대로 x값을 입력\n",
    "    for i in range(width):\n",
    "        gaussian[i] = math.exp(-gaussian[i] ** 2 / (2 * sigma ** 2))  # x값에 따라 gaussian값 획득 및 입력\n",
    "\n",
    "    # 아래는 normalize, 전체 합으로 각 엔트리를 나눈다.\n",
    "    kernal_sum = np.sum(gaussian)\n",
    "    for i in range(width):\n",
    "        gaussian[i] /= kernal_sum\n",
    "    return gaussian\n",
    "\n",
    "def gauss2d(sigma):\n",
    "    return np.outer(gauss1d(sigma), gauss1d(sigma))\n",
    "# outer product로 2d 가우시안 필터를 구한다.\n",
    "\n",
    "def convolve2d(array, filter):\n",
    "    padding_width = int(len(filter) / 2)  # filter에 따른 padding 크기\n",
    "    zero_padding = np.zeros((np.shape(array)[0] + padding_width * 2,\n",
    "                             np.shape(array)[1] + padding_width * 2))\n",
    "    # padding한 크기에 맞게 새로운 np.array를 생성\n",
    "\n",
    "    # convolution연산을 위해서 filter를 축의 방향에 대해서 뒤집는다.\n",
    "    flipped_filter = np.flip(filter, axis=0)\n",
    "    flipped_filter = np.flip(flipped_filter, axis=1)\n",
    "    # 모든 픽셀에 대해서 paading을 제외한 부분에 array를 집어넣어 준다.\n",
    "    for i in range(padding_width, np.shape(zero_padding)[0] - padding_width):\n",
    "        for j in range(padding_width, np.shape(zero_padding)[1] - padding_width):\n",
    "            zero_padding[i][j] = array[i - padding_width][j - padding_width]\n",
    "\n",
    "    # padding된 이미지의 각 픽셀을 순회하면서 각 픽셀에 컨벌루젼한 값을 입력한다.\n",
    "\n",
    "    convolved = np.zeros(np.shape(array))\n",
    "\n",
    "    for i in range(padding_width, np.shape(zero_padding)[0] - padding_width):\n",
    "        for j in range(padding_width, np.shape(zero_padding)[1] - padding_width):\n",
    "            subpart = zero_padding[i - padding_width:i + padding_width + 1,\n",
    "                      j - padding_width:j + padding_width + 1]\n",
    "            convolved[i-padding_width][j-padding_width] = np.sum(subpart * flipped_filter)\n",
    "    # 컨벌루젼한 값을 리턴\n",
    "    return convolved\n",
    "\n",
    "def gaussconvolve2d(array, sigma):\n",
    "    return convolve2d(array, gauss2d(sigma))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# 이구아나 사진을 불러온다.\n",
    "iguana_img = Image.open('iguana.bmp')\n",
    "# 사진을 흑백처리한다.\n",
    "iguana_img_grey = iguana_img.convert('L')\n",
    "# 이미지를 np 배열형태로 변형한다.\n",
    "iguana_array_grey = np.asarray(iguana_img_grey)\n",
    "# 가우시안 필터 효과를 적용한다.\n",
    "iguana_array_grey_blur = np.uint8(gaussconvolve2d(iguana_array_grey, 1.6))\n",
    "# 배열을 이미지로 변경하여 보여준다.\n",
    "Image.fromarray(iguana_array_grey_blur).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "#sobel연산을 위한 필터를 제작한다. normalization을 위해 8로 나눈다.\n",
    "x_sobel = np.array([ 1, 0, -1, 2, 0, -2, 1, 0, -1])\n",
    "y_sobel = np.array([ 1, 2, 1, 0, 0, 0, -1, -2, -1])\n",
    "x_sobel = x_sobel.reshape((3, 3))/8.0\n",
    "y_sobel = y_sobel.reshape((3, 3))/8.0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# sobel\n",
    "x_gradient_iguana = convolve2d(iguana_array_grey_blur, x_sobel)\n",
    "y_gradient_iguana = convolve2d(iguana_array_grey_blur, y_sobel)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "sum_gradient_iguana = np.hypot(x_gradient_iguana, y_gradient_iguana)\n",
    "mapped_sum_gradient_iguana = (sum_gradient_iguana / np.max(sum_gradient_iguana)) * 255"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "Image.fromarray(mapped_sum_gradient_iguana).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 45.          77.15229514  86.42366563 ... -84.55966797 -75.5432446\n",
      "  -44.6527571 ]\n",
      " [ 15.42216132  50.19442891  75.46554492 ... -68.02549201 -43.85423716\n",
      "  -13.77366153]\n",
      " [  7.65065096  29.475889    60.2551187  ... -47.91083783 -23.78203042\n",
      "   -6.38282253]\n",
      " ...\n",
      " [ 13.39249775  39.09385889  54.78240703 ... -89.99999673  57.72435569\n",
      "   13.70230016]\n",
      " [  3.17983012  11.88865804  21.80140949 ... -83.57652956  72.09555249\n",
      "   20.58445165]\n",
      " [-39.28940686 -67.93210044 -75.37912601 ... -85.04154908  85.19204604\n",
      "   48.27048792]]\n",
      "89.99999889283518\n",
      "-89.99999934331485\n",
      "------\n",
      "[[ 1.  2.  2. ... -2. -2. -1.]\n",
      " [ 0.  1.  2. ... -2. -1.  0.]\n",
      " [ 0.  1.  1. ... -1. -1.  0.]\n",
      " ...\n",
      " [ 0.  1.  1. ... -2.  1.  0.]\n",
      " [ 0.  0.  0. ... -2.  2.  0.]\n",
      " [-1. -2. -2. ... -2.  2.  1.]]\n",
      "2.0\n",
      "-2.0\n"
     ]
    }
   ],
   "source": [
    "vectorized_arctan = np.vectorize(np.arctan)\n",
    "x_gradient_iguana[x_gradient_iguana==0] = 0.000001\n",
    "theta = vectorized_arctan(y_gradient_iguana/x_gradient_iguana)\n",
    "\n",
    "theta_degree = theta * 180 / np.pi\n",
    "# 변환된 각도에 따라 매핑한다. 매핑은 0 ~\n",
    "theta_mapped = (theta_degree + 22.5) // 45\n",
    "print(theta_degree)\n",
    "print(np.max(theta_degree))\n",
    "print(np.min(theta_degree))\n",
    "print(\"------\")\n",
    "print(theta_mapped)\n",
    "print(np.max(theta_mapped))\n",
    "print(np.min(theta_mapped))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "theta 를 매핑하고 0/45/90/135\n",
    "매핑된 결과에 따라서 가장 큰 값을 적용"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def remain_max(array, x, y, angle):\n",
    "    ret = 0\n",
    "    if angle == -2 or angle == 2:\n",
    "        if array[y][x] < max(array[y+1][x], array[y][x], array[y-1][x]):\n",
    "            ret = 0\n",
    "        else:\n",
    "            ret =  array[y][x]\n",
    "    if angle == -1:\n",
    "        if array[y][x] < max(array[y+1][x-1], array[y][x], array[y-1][x+1]):\n",
    "            ret =  0\n",
    "        else:\n",
    "            ret =  array[y][x]\n",
    "    if angle == 0:\n",
    "        if array[y][x] < max(array[y][x+1], array[y][x], array[y][x-1]):\n",
    "            ret = 0\n",
    "        else:\n",
    "            ret = array[y][x]\n",
    "    if angle == 1:\n",
    "        if array[y][x] < max(array[y+1][x+1], array[y][x], array[y-1][x-1]):\n",
    "            ret = 0\n",
    "        else:\n",
    "            ret = array[y][x]\n",
    "    return ret"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "res = np.zeros(np.shape(mapped_sum_gradient_iguana))\n",
    "for row in range(1, len(mapped_sum_gradient_iguana)-1):\n",
    "    for col in range(1, len(mapped_sum_gradient_iguana[1])-1):\n",
    "        res[row][col] = \\\n",
    "            remain_max(mapped_sum_gradient_iguana, col, row, theta_mapped[row][col])\n",
    "Image.fromarray(res).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def theta_mapping(angle):\n",
    "    if angle == -2 or angle == 2:\n",
    "        return np.array([128,0,0])\n",
    "    if angle == -1:\n",
    "        return np.array([0,128,0])\n",
    "    if angle == 0:\n",
    "        return np.array([0,0,128])\n",
    "    if angle == 1:\n",
    "        return np.array([128,128,128])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[128. 128. 128.]\n",
      "  [128.   0.   0.]\n",
      "  [128.   0.   0.]\n",
      "  ...\n",
      "  [128.   0.   0.]\n",
      "  [128.   0.   0.]\n",
      "  [  0. 128.   0.]]\n",
      "\n",
      " [[  0.   0. 128.]\n",
      "  [128. 128. 128.]\n",
      "  [128.   0.   0.]\n",
      "  ...\n",
      "  [128.   0.   0.]\n",
      "  [  0. 128.   0.]\n",
      "  [  0.   0. 128.]]\n",
      "\n",
      " [[  0.   0. 128.]\n",
      "  [128. 128. 128.]\n",
      "  [128. 128. 128.]\n",
      "  ...\n",
      "  [  0. 128.   0.]\n",
      "  [  0. 128.   0.]\n",
      "  [  0.   0. 128.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0.   0. 128.]\n",
      "  [128. 128. 128.]\n",
      "  [128. 128. 128.]\n",
      "  ...\n",
      "  [128.   0.   0.]\n",
      "  [128. 128. 128.]\n",
      "  [  0.   0. 128.]]\n",
      "\n",
      " [[  0.   0. 128.]\n",
      "  [  0.   0. 128.]\n",
      "  [  0.   0. 128.]\n",
      "  ...\n",
      "  [128.   0.   0.]\n",
      "  [128.   0.   0.]\n",
      "  [  0.   0. 128.]]\n",
      "\n",
      " [[  0. 128.   0.]\n",
      "  [128.   0.   0.]\n",
      "  [128.   0.   0.]\n",
      "  ...\n",
      "  [128.   0.   0.]\n",
      "  [128.   0.   0.]\n",
      "  [128. 128. 128.]]]\n"
     ]
    }
   ],
   "source": [
    "mapped_theta = np.zeros((len(theta), len(theta[0]), 3))\n",
    "for i in range(len(mapped_theta)):\n",
    "    for j in range(len(mapped_theta[0])):\n",
    "        for k in range(3):\n",
    "            mapped_theta[i][j][k] = theta_mapping(theta_mapped[i][j])[k]\n",
    "\n",
    "print(mapped_theta)\n",
    "Image.fromarray(mapped_theta.astype(np.uint8)).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Theta는 제대로 작동하는 것처럼 보이는데...."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def apply_double_threshold(entry, T_high, T_low):\n",
    "    if entry >= T_high:\n",
    "        return 255\n",
    "    elif T_high > entry >= T_low:\n",
    "        return 80\n",
    "    else:\n",
    "        return 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def double_thresholding(img):\n",
    "    diff = img.max() - img.min()\n",
    "    T_high = img.min() + diff * 0.15\n",
    "    T_low = img.min() + diff * 0.03\n",
    "\n",
    "    res = img[:]\n",
    "\n",
    "    vectorized_threshold = np.vectorize(apply_double_threshold)\n",
    "    res = vectorized_threshold(img, T_high, T_low)\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W) representing NMS edge response.\n",
    "    Returns:\n",
    "        res: double_thresholded image.\n",
    "    \"\"\"\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "double_thresholded = double_thresholding(res)\n",
    "Image.fromarray(double_thresholded.astype(np.uint8)).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "def dfs(img, res, i, j, visited=[]):\n",
    "    # 호출된 시점의 시작점 (i, j)은 최초 호출이 아닌 이상\n",
    "    # strong 과 연결된 weak 포인트이므로 res에 strong 값을 준다\n",
    "    res[i, j] = 255\n",
    "\n",
    "    # 이미 방문했음을 표시한다\n",
    "    visited.append((i, j))\n",
    "\n",
    "    # (i, j)에 연결된 8가지 방향을 모두 검사하여 weak 포인트가 있다면 재귀적으로 호출\n",
    "    for ii in range(i-1, i+2) :\n",
    "        for jj in range(j-1, j+2) :\n",
    "            if (img[ii, jj] == 80) and ((ii, jj) not in visited) :\n",
    "                dfs(img, res, ii, jj, visited)\n",
    "\n",
    "def hysteresis(img):\n",
    "    res = np.zeros(np.shape(img))\n",
    "    visited = []\n",
    "    width = len(img)\n",
    "    height = len(img[0])\n",
    "    for i in range(1, width-1):\n",
    "        for j in range(1, height-1):\n",
    "            if img[i][j] == 255:\n",
    "                dfs(img, res, i, j, visited)\n",
    "    \"\"\" Find weak edges connected to strong edges and link them.\n",
    "    Iterate over each pixel in strong_edges and perform depth first\n",
    "    search across the connected pixels in weak_edges to link them.\n",
    "    Here we consider a pixel (a, b) is connected to a pixel (c, d)\n",
    "    if (a, b) is one of the eight neighboring pixels of (c, d).\n",
    "    Args:\n",
    "        img: numpy array of shape (H, W) representing NMS edge response.\n",
    "    Returns:\n",
    "        res: hysteresised image.\n",
    "    \"\"\"\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [
    "hysteresised = hysteresis(double_thresholded)\n",
    "Image.fromarray(hysteresised.astype(np.uint8)).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
